# -*- coding: utf-8 -*-
"""An√°lise de sentimentos com NLTK.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13NWIPIE6UPS6kVT9oNyaoxygE0JbJsZC
"""

pip install nltk==3.3

import nltk

nltk.download('twitter_samples')
nltk.download('wordnet')

from nltk.corpus import twitter_samples 
positive_tweets = twitter_samples.strings('positive_tweets.json') 
negative_tweets = twitter_samples.strings('negative_tweets.json') 
text = twitter_samples.strings('tweets.20150430-223406.json') 
tweet_tokens = twitter_samples.tokenized('positive_tweets.json')[0]
print(tweet_tokens[0])

tweet_tokens = twitter_samples.tokenized('positive_tweets.json')
print(tweet_tokens[0])

from nltk.tag import pos_tag
from nltk.stem.wordnet import WordNetLemmatizer 
#nltk.download('averaged_perceptron_tagger')
#nltk.download('wordnet')
#nltk.download('omw-1.4')
#nltk.download('stopwords')

  
def lemmatize_sentence(tokens):
  lemmatizer = WordNetLemmatizer()
  lemmatized_sentence = []   
  for word, tag in pos_tag(tokens):
    if tag.startswith('NN'):
      pos = 'n'
    elif tag.startswith('VB'):
      pos = 'v'
    else:
      pos = 'a'
    lemmatized_sentence.append(lemmatizer.lemmatize(word, pos))
  return lemmatized_sentence 
print(lemmatize_sentence(tweet_tokens[0]))

from nltk.tag import pos_tag
from nltk.stem.wordnet import WordNetLemmatizer 
def lemmatize_sentence(tokens):
    lemmatizer = WordNetLemmatizer()
    lemmatized_sentence = []    
    for word, tag in pos_tag(tokens):
        if tag.startswith('NN'):
            pos = 'n'
        elif tag.startswith('VB'):
            pos = 'v'
        else:
            pos = 'a'
    lemmatized_sentence.append(lemmatizer.lemmatize(word, pos))
    return lemmatized_sentence 
print(lemmatize_sentence(tweet_tokens))



